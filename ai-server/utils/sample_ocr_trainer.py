#!/usr/bin/env python3
"""
ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ OCR í›ˆë ¨ ìœ í‹¸ë¦¬í‹°
AI í—ˆë¸Œì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ìƒ˜í”Œ ë°ì´í„°ë¡œ OCR ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import os
import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple

logger = logging.getLogger(__name__)

class SampleOCRTrainer:
    def __init__(self, dataset_path: str = "sample_ocr_dataset"):
        """
        ìƒ˜í”Œ OCR í›ˆë ¨ê¸° ì´ˆê¸°í™”
        
        Args:
            dataset_path: ìƒ˜í”Œ ë°ì´í„°ì…‹ ê²½ë¡œ
        """
        self.dataset_path = Path(dataset_path)
        # AI í—ˆë¸Œ ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ê²½ë¡œ ì„¤ì •
        self.label_path = self.dataset_path / "Sample" / "02.ë¼ë²¨ë§ë°ì´í„°" / "OCR"
        
    def extract_sample_dataset(self, zip_path: str) -> bool:
        """
        ìƒ˜í”Œ ë°ì´í„°ì…‹ ZIP íŒŒì¼ ì¶”ì¶œ
        
        Args:
            zip_path: ìƒ˜í”Œ ë°ì´í„°ì…‹ ZIP íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            import zipfile
            
            logger.info(f"ìƒ˜í”Œ ë°ì´í„°ì…‹ ì¶”ì¶œ ì¤‘: {zip_path}")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # ëª¨ë“  íŒŒì¼ ì¶”ì¶œ (ìƒ˜í”Œì´ë¯€ë¡œ ì „ì²´)
                zip_ref.extractall(self.dataset_path)
            
            logger.info("âœ… ìƒ˜í”Œ ë°ì´í„°ì…‹ ì¶”ì¶œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìƒ˜í”Œ ë°ì´í„°ì…‹ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_sample_structure(self) -> Dict:
        """
        ìƒ˜í”Œ ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„
        
        Returns:
            ë°ì´í„°ì…‹ ì •ë³´
        """
        info = {
            "json_files": 0,
            "total_files": 0,
            "sample_files": [],
            "categories": set()
        }
        
        # JSON ë¼ë²¨ íŒŒì¼ ìˆ˜ ê³„ì‚°
        if self.label_path.exists():
            json_files = list(self.label_path.glob("**/*.json"))
            info["json_files"] = len(json_files)
            info["total_files"] = len(json_files)
            
            # íŒŒì¼ ë¶„ì„
            for json_file in json_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ë¶„ì„
                info["sample_files"].append(json_file.name)
                # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ (í´ë”ëª…)
                category = json_file.parent.name
                info["categories"].add(category)
        
        # JSON ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ë¶„ì„
        json_files = list(self.dataset_path.glob("**/*.json"))
        if json_files:
            try:
                with open(json_files[0], 'r', encoding='utf-8') as f:
                    sample_data = json.load(f)
                    logger.info(f"ìƒ˜í”Œ JSON êµ¬ì¡°: {type(sample_data)}")
                    if isinstance(sample_data, list):
                        logger.info(f"JSON ë°°ì—´ ê¸¸ì´: {len(sample_data)}")
                    elif isinstance(sample_data, dict):
                        logger.info(f"JSON í‚¤ë“¤: {list(sample_data.keys())}")
            except Exception as e:
                logger.warning(f"JSON íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return info
    
    def prepare_sample_training_data(self) -> Tuple[List[str], List[str]]:
        """
        ìƒ˜í”Œ í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
        
        Returns:
            (ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, í…ìŠ¤íŠ¸ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸)
        """
        image_paths = []
        text_labels = []
        
        # JSON ë¼ë²¨ íŒŒì¼ë“¤ ì°¾ê¸°
        if self.label_path.exists():
            json_files = list(self.label_path.glob("**/*.json"))
            
            for json_file in json_files:
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        label_data = json.load(f)
                        
                        # AI í—ˆë¸Œ JSON êµ¬ì¡° ë¶„ì„
                        if isinstance(label_data, dict):
                            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
                            if 'Images' in label_data and 'file_name' in label_data['Images']:
                                img_path = str(label_data['Images']['file_name'])
                                image_paths.append(img_path)
                            
                            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ)
                            if 'annotations' in label_data:
                                texts = []
                                for annotation in label_data['annotations']:
                                    if 'text' in annotation:
                                        texts.append(annotation['text'])
                                if texts:
                                    text_labels.append(' '.join(texts))
                            elif 'text' in label_data:
                                # ì§ì ‘ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°
                                text_labels.append(label_data['text'])
                                
                        elif isinstance(label_data, list):
                            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì–´ë…¸í…Œì´ì…˜
                            texts = []
                            for item in label_data:
                                if isinstance(item, dict) and 'text' in item:
                                    texts.append(item['text'])
                            if texts:
                                text_labels.append(' '.join(texts))
                                
                except Exception as e:
                    logger.warning(f"ë¼ë²¨ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {json_file}: {e}")
        
        logger.info(f"ìƒ˜í”Œ í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(image_paths)}ê°œ ì´ë¯¸ì§€, {len(text_labels)}ê°œ í…ìŠ¤íŠ¸")
        return image_paths, text_labels
    
    def train_sample_model(self, output_path: str = "models/sample_ocr") -> bool:
        """
        ìƒ˜í”Œ ë°ì´í„°ë¡œ OCR ëª¨ë¸ í›ˆë ¨
        
        Args:
            output_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            
        Returns:
            í›ˆë ¨ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
            image_paths, text_labels = self.prepare_sample_training_data()
            
            if len(image_paths) == 0:
                logger.error("âŒ ìƒ˜í”Œ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            logger.info(f"ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {len(image_paths)}ê°œ ì´ë¯¸ì§€")
            
            # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(output_path, exist_ok=True)
            
            # í›ˆë ¨ ë°ì´í„° ì •ë³´ ì €ì¥
            dataset_info = self.analyze_sample_structure()
            # setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ)
            if 'categories' in dataset_info:
                dataset_info['categories'] = list(dataset_info['categories'])
            
            training_info = {
                "total_images": len(image_paths),
                "sample_texts": text_labels[:5],  # ìƒ˜í”Œ í…ìŠ¤íŠ¸
                "dataset_info": dataset_info,
                "model_type": "sample_ocr"
            }
            
            with open(f"{output_path}/training_info.json", 'w', encoding='utf-8') as f:
                json.dump(training_info, f, ensure_ascii=False, indent=2)
            
            logger.info("âœ… ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ìƒ˜í”Œ ë°ì´í„°ì…‹ ZIP íŒŒì¼ ê²½ë¡œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì´ë¦„)
    possible_zip_files = [
        "sample_ocr_dataset.zip",           # ê¶Œì¥
        "aihub_multilingual_ocr_dataset.zip",
        "aihub_ocr_dataset.zip", 
        "multilingual_ocr_dataset.zip",
        "train.zip",
        "ocr_dataset.zip"
    ]
    
    zip_path = None
    for file_name in possible_zip_files:
        if os.path.exists(file_name):
            zip_path = file_name
            break
    
    if not zip_path:
        logger.error(f"âŒ ìƒ˜í”Œ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ íŒŒì¼ ì¤‘ í•˜ë‚˜ë¥¼ ë„£ì–´ì£¼ì„¸ìš”:")
        for file_name in possible_zip_files:
            logger.error(f"   - {file_name}")
        return
    
    # í›ˆë ¨ê¸° ì´ˆê¸°í™”
    trainer = SampleOCRTrainer()
    
    # ë°ì´í„°ì…‹ ì¶”ì¶œ
    if trainer.extract_sample_dataset(zip_path):
        # ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„
        info = trainer.analyze_sample_structure()
        logger.info(f"ìƒ˜í”Œ ë°ì´í„°ì…‹ ì •ë³´: {info}")
        
        # ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨
        if trainer.train_sample_model():
            logger.info("ğŸ‰ ìƒ˜í”Œ ë°ì´í„°ì…‹ ê¸°ë°˜ OCR ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        else:
            logger.error("âŒ ìƒ˜í”Œ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
    else:
        logger.error("âŒ ìƒ˜í”Œ ë°ì´í„°ì…‹ ì¶”ì¶œ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 